{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.read_csv('Iris.csv')\n",
    "df.Species= pd.factorize(df.Species)[0] + 1\n",
    "df\n",
    "labels=df.iloc[0:,-1]\n",
    "features=df.iloc[:,1:-1]\n",
    "features=features.astype(np.float32)\n",
    "labels=labels.astype(np.float32)\n",
    "\n",
    "\n",
    "# data = data[0:-1]\n",
    "# print(features)\n",
    "# print(labels)\n",
    "# train_tensor = torch.tensor(train.values)\n",
    "\n",
    "inputs = torch.from_numpy(features.values)\n",
    "targets = torch.from_numpy(labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
      "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
      "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
      "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
      "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
      "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
      "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.1000],\n",
      "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
      "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
      "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
      "        [5.4000, 3.9000, 1.3000, 0.4000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
      "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
      "        [5.1000, 3.8000, 1.5000, 0.3000],\n",
      "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
      "        [5.1000, 3.7000, 1.5000, 0.4000],\n",
      "        [4.6000, 3.6000, 1.0000, 0.2000],\n",
      "        [5.1000, 3.3000, 1.7000, 0.5000],\n",
      "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
      "        [5.0000, 3.0000, 1.6000, 0.2000],\n",
      "        [5.0000, 3.4000, 1.6000, 0.4000],\n",
      "        [5.2000, 3.5000, 1.5000, 0.2000],\n",
      "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.6000, 0.2000],\n",
      "        [4.8000, 3.1000, 1.6000, 0.2000],\n",
      "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
      "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
      "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [5.0000, 3.2000, 1.2000, 0.2000],\n",
      "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [4.4000, 3.0000, 1.3000, 0.2000],\n",
      "        [5.1000, 3.4000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
      "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
      "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
      "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
      "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.3000],\n",
      "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
      "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
      "        [5.3000, 3.7000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.3000, 1.4000, 0.2000],\n",
      "        [7.0000, 3.2000, 4.7000, 1.4000],\n",
      "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
      "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
      "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
      "        [6.5000, 2.8000, 4.6000, 1.5000],\n",
      "        [5.7000, 2.8000, 4.5000, 1.3000],\n",
      "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
      "        [4.9000, 2.4000, 3.3000, 1.0000],\n",
      "        [6.6000, 2.9000, 4.6000, 1.3000],\n",
      "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
      "        [5.0000, 2.0000, 3.5000, 1.0000],\n",
      "        [5.9000, 3.0000, 4.2000, 1.5000],\n",
      "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
      "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
      "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
      "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
      "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
      "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
      "        [6.2000, 2.2000, 4.5000, 1.5000],\n",
      "        [5.6000, 2.5000, 3.9000, 1.1000],\n",
      "        [5.9000, 3.2000, 4.8000, 1.8000],\n",
      "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
      "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
      "        [6.1000, 2.8000, 4.7000, 1.2000],\n",
      "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
      "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
      "        [6.8000, 2.8000, 4.8000, 1.4000],\n",
      "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
      "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
      "        [5.7000, 2.6000, 3.5000, 1.0000],\n",
      "        [5.5000, 2.4000, 3.8000, 1.1000],\n",
      "        [5.5000, 2.4000, 3.7000, 1.0000],\n",
      "        [5.8000, 2.7000, 3.9000, 1.2000],\n",
      "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
      "        [5.4000, 3.0000, 4.5000, 1.5000],\n",
      "        [6.0000, 3.4000, 4.5000, 1.6000],\n",
      "        [6.7000, 3.1000, 4.7000, 1.5000],\n",
      "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
      "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
      "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
      "        [5.5000, 2.6000, 4.4000, 1.2000],\n",
      "        [6.1000, 3.0000, 4.6000, 1.4000],\n",
      "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
      "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
      "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
      "        [5.7000, 3.0000, 4.2000, 1.2000],\n",
      "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
      "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
      "        [5.1000, 2.5000, 3.0000, 1.1000],\n",
      "        [5.7000, 2.8000, 4.1000, 1.3000],\n",
      "        [6.3000, 3.3000, 6.0000, 2.5000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [7.1000, 3.0000, 5.9000, 2.1000],\n",
      "        [6.3000, 2.9000, 5.6000, 1.8000],\n",
      "        [6.5000, 3.0000, 5.8000, 2.2000],\n",
      "        [7.6000, 3.0000, 6.6000, 2.1000],\n",
      "        [4.9000, 2.5000, 4.5000, 1.7000],\n",
      "        [7.3000, 2.9000, 6.3000, 1.8000],\n",
      "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
      "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
      "        [6.5000, 3.2000, 5.1000, 2.0000],\n",
      "        [6.4000, 2.7000, 5.3000, 1.9000],\n",
      "        [6.8000, 3.0000, 5.5000, 2.1000],\n",
      "        [5.7000, 2.5000, 5.0000, 2.0000],\n",
      "        [5.8000, 2.8000, 5.1000, 2.4000],\n",
      "        [6.4000, 3.2000, 5.3000, 2.3000],\n",
      "        [6.5000, 3.0000, 5.5000, 1.8000],\n",
      "        [7.7000, 3.8000, 6.7000, 2.2000],\n",
      "        [7.7000, 2.6000, 6.9000, 2.3000],\n",
      "        [6.0000, 2.2000, 5.0000, 1.5000],\n",
      "        [6.9000, 3.2000, 5.7000, 2.3000],\n",
      "        [5.6000, 2.8000, 4.9000, 2.0000],\n",
      "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
      "        [6.3000, 2.7000, 4.9000, 1.8000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
      "        [7.2000, 3.2000, 6.0000, 1.8000],\n",
      "        [6.2000, 2.8000, 4.8000, 1.8000],\n",
      "        [6.1000, 3.0000, 4.9000, 1.8000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.1000],\n",
      "        [7.2000, 3.0000, 5.8000, 1.6000],\n",
      "        [7.4000, 2.8000, 6.1000, 1.9000],\n",
      "        [7.9000, 3.8000, 6.4000, 2.0000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.2000],\n",
      "        [6.3000, 2.8000, 5.1000, 1.5000],\n",
      "        [6.1000, 2.6000, 5.6000, 1.4000],\n",
      "        [7.7000, 3.0000, 6.1000, 2.3000],\n",
      "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
      "        [6.4000, 3.1000, 5.5000, 1.8000],\n",
      "        [6.0000, 3.0000, 4.8000, 1.8000],\n",
      "        [6.9000, 3.1000, 5.4000, 2.1000],\n",
      "        [6.7000, 3.1000, 5.6000, 2.4000],\n",
      "        [6.9000, 3.1000, 5.1000, 2.3000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [6.8000, 3.2000, 5.9000, 2.3000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.5000],\n",
      "        [6.7000, 3.0000, 5.2000, 2.3000],\n",
      "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
      "        [6.5000, 3.0000, 5.2000, 2.0000],\n",
      "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
      "        [5.9000, 3.0000, 5.1000, 1.8000]])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2518, -0.4774, -0.4959, -0.3860]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0577], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(4, 1)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(inputs.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6687],\n",
       "        [-3.3797],\n",
       "        [-3.3752],\n",
       "        [-3.4015],\n",
       "        [-3.6913],\n",
       "        [-4.1612],\n",
       "        [-3.5337],\n",
       "        [-3.6454],\n",
       "        [-3.2060],\n",
       "        [-3.4384],\n",
       "        [-3.8893],\n",
       "        [-3.6446],\n",
       "        [-3.3159],\n",
       "        [-3.0412],\n",
       "        [-3.9844],\n",
       "        [-4.3762],\n",
       "        [-3.9628],\n",
       "        [-3.7073],\n",
       "        [-4.1504],\n",
       "        [-3.9001],\n",
       "        [-3.8453],\n",
       "        [-3.8910],\n",
       "        [-3.3922],\n",
       "        [-3.8378],\n",
       "        [-3.7934],\n",
       "        [-3.5040],\n",
       "        [-3.7722],\n",
       "        [-3.7435],\n",
       "        [-3.6461],\n",
       "        [-3.5240],\n",
       "        [-3.5014],\n",
       "        [-3.8233],\n",
       "        [-3.9913],\n",
       "        [-4.1036],\n",
       "        [-3.4384],\n",
       "        [-3.4011],\n",
       "        [-3.7198],\n",
       "        [-3.4384],\n",
       "        [-3.2042],\n",
       "        [-3.6706],\n",
       "        [-3.6325],\n",
       "        [-2.9338],\n",
       "        [-3.2996],\n",
       "        [-3.8971],\n",
       "        [-4.1371],\n",
       "        [-3.3931],\n",
       "        [-3.9111],\n",
       "        [-3.3996],\n",
       "        [-3.8641],\n",
       "        [-3.5480],\n",
       "        [-6.1037],\n",
       "        [-5.8920],\n",
       "        [-6.1686],\n",
       "        [-4.9106],\n",
       "        [-5.7759],\n",
       "        [-5.4476],\n",
       "        [-6.0524],\n",
       "        [-4.3443],\n",
       "        [-5.7716],\n",
       "        [-5.0151],\n",
       "        [-4.2778],\n",
       "        [-5.5219],\n",
       "        [-4.8730],\n",
       "        [-5.7339],\n",
       "        [-5.0239],\n",
       "        [-5.8316],\n",
       "        [-5.5951],\n",
       "        [-5.1109],\n",
       "        [-5.3643],\n",
       "        [-4.9045],\n",
       "        [-6.0307],\n",
       "        [-5.3004],\n",
       "        [-5.7311],\n",
       "        [-5.6089],\n",
       "        [-5.5724],\n",
       "        [-5.7587],\n",
       "        [-5.9120],\n",
       "        [-6.1973],\n",
       "        [-5.6481],\n",
       "        [-4.7404],\n",
       "        [-4.7820],\n",
       "        [-4.6938],\n",
       "        [-5.0889],\n",
       "        [-5.8888],\n",
       "        [-5.5448],\n",
       "        [-5.9254],\n",
       "        [-6.0190],\n",
       "        [-5.3104],\n",
       "        [-5.3196],\n",
       "        [-5.0061],\n",
       "        [-5.2136],\n",
       "        [-5.7320],\n",
       "        [-5.0908],\n",
       "        [-4.3218],\n",
       "        [-5.2260],\n",
       "        [-5.3557],\n",
       "        [-5.3466],\n",
       "        [-5.5221],\n",
       "        [-4.3323],\n",
       "        [-5.2493],\n",
       "        [-7.0445],\n",
       "        [-5.9543],\n",
       "        [-6.8987],\n",
       "        [-6.3850],\n",
       "        [-6.7367],\n",
       "        [-7.3718],\n",
       "        [-5.2574],\n",
       "        [-6.9839],\n",
       "        [-6.3940],\n",
       "        [-7.4639],\n",
       "        [-6.4078],\n",
       "        [-6.2045],\n",
       "        [-6.6248],\n",
       "        [-5.8226],\n",
       "        [-6.1950],\n",
       "        [-6.5976],\n",
       "        [-6.4335],\n",
       "        [-7.8671],\n",
       "        [-7.4320],\n",
       "        [-5.5619],\n",
       "        [-6.9219],\n",
       "        [-5.8911],\n",
       "        [-7.3125],\n",
       "        [-5.9424],\n",
       "        [-6.8421],\n",
       "        [-6.9532],\n",
       "        [-5.9153],\n",
       "        [-6.0352],\n",
       "        [-6.4782],\n",
       "        [-6.6813],\n",
       "        [-6.9008],\n",
       "        [-7.6914],\n",
       "        [-6.5168],\n",
       "        [-5.9735],\n",
       "        [-6.0370],\n",
       "        [-7.2262],\n",
       "        [-6.8553],\n",
       "        [-6.4561],\n",
       "        [-5.9604],\n",
       "        [-6.6482],\n",
       "        [-6.8128],\n",
       "        [-6.5766],\n",
       "        [-5.9543],\n",
       "        [-6.9959],\n",
       "        [-6.9965],\n",
       "        [-6.5281],\n",
       "        [-5.9351],\n",
       "        [-6.3619],\n",
       "        [-6.6923],\n",
       "        [-6.0840]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(model(inputs), targets.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(56.0529, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6g/wyvpg_nj08xb0l9l4rm1mndh0000gn/T/ipykernel_27136/4082622962.py:14: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = loss_fn(pred, yb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/950], Loss: 25.2040\n",
      "Epoch [20/950], Loss: 15.4744\n",
      "Epoch [30/950], Loss: 7.6385\n",
      "Epoch [40/950], Loss: 3.4421\n",
      "Epoch [50/950], Loss: 0.6378\n",
      "Epoch [60/950], Loss: 1.6102\n",
      "Epoch [70/950], Loss: 1.1185\n",
      "Epoch [80/950], Loss: 0.6418\n",
      "Epoch [90/950], Loss: 0.5723\n",
      "Epoch [100/950], Loss: 0.9602\n",
      "Epoch [110/950], Loss: 0.9297\n",
      "Epoch [120/950], Loss: 0.5693\n",
      "Epoch [130/950], Loss: 0.4464\n",
      "Epoch [140/950], Loss: 0.8370\n",
      "Epoch [150/950], Loss: 0.8601\n",
      "Epoch [160/950], Loss: 0.1745\n",
      "Epoch [170/950], Loss: 0.6516\n",
      "Epoch [180/950], Loss: 0.5456\n",
      "Epoch [190/950], Loss: 0.6822\n",
      "Epoch [200/950], Loss: 0.7215\n",
      "Epoch [210/950], Loss: 0.8504\n",
      "Epoch [220/950], Loss: 0.4171\n",
      "Epoch [230/950], Loss: 0.4463\n",
      "Epoch [240/950], Loss: 0.8416\n",
      "Epoch [250/950], Loss: 0.4858\n",
      "Epoch [260/950], Loss: 0.6037\n",
      "Epoch [270/950], Loss: 0.6269\n",
      "Epoch [280/950], Loss: 0.7679\n",
      "Epoch [290/950], Loss: 0.4175\n",
      "Epoch [300/950], Loss: 0.6014\n",
      "Epoch [310/950], Loss: 0.4274\n",
      "Epoch [320/950], Loss: 0.8698\n",
      "Epoch [330/950], Loss: 0.4317\n",
      "Epoch [340/950], Loss: 1.0697\n",
      "Epoch [350/950], Loss: 0.2433\n",
      "Epoch [360/950], Loss: 0.6422\n",
      "Epoch [370/950], Loss: 0.2388\n",
      "Epoch [380/950], Loss: 0.8844\n",
      "Epoch [390/950], Loss: 0.8915\n",
      "Epoch [400/950], Loss: 0.5369\n",
      "Epoch [410/950], Loss: 0.6538\n",
      "Epoch [420/950], Loss: 0.5779\n",
      "Epoch [430/950], Loss: 0.6135\n",
      "Epoch [440/950], Loss: 0.4077\n",
      "Epoch [450/950], Loss: 0.6824\n",
      "Epoch [460/950], Loss: 0.6016\n",
      "Epoch [470/950], Loss: 0.7118\n",
      "Epoch [480/950], Loss: 0.7387\n",
      "Epoch [490/950], Loss: 0.6512\n",
      "Epoch [500/950], Loss: 0.8751\n",
      "Epoch [510/950], Loss: 0.5800\n",
      "Epoch [520/950], Loss: 0.2020\n",
      "Epoch [530/950], Loss: 0.5326\n",
      "Epoch [540/950], Loss: 0.9470\n",
      "Epoch [550/950], Loss: 0.5832\n",
      "Epoch [560/950], Loss: 0.6321\n",
      "Epoch [570/950], Loss: 0.8424\n",
      "Epoch [580/950], Loss: 0.7242\n",
      "Epoch [590/950], Loss: 0.5724\n",
      "Epoch [600/950], Loss: 0.5605\n",
      "Epoch [610/950], Loss: 0.8813\n",
      "Epoch [620/950], Loss: 0.8844\n",
      "Epoch [630/950], Loss: 0.3253\n",
      "Epoch [640/950], Loss: 0.3966\n",
      "Epoch [650/950], Loss: 0.4492\n",
      "Epoch [660/950], Loss: 0.7697\n",
      "Epoch [670/950], Loss: 0.9787\n",
      "Epoch [680/950], Loss: 0.5937\n",
      "Epoch [690/950], Loss: 0.8000\n",
      "Epoch [700/950], Loss: 0.7427\n",
      "Epoch [710/950], Loss: 0.5323\n",
      "Epoch [720/950], Loss: 0.2440\n",
      "Epoch [730/950], Loss: 0.9251\n",
      "Epoch [740/950], Loss: 1.0097\n",
      "Epoch [750/950], Loss: 0.6925\n",
      "Epoch [760/950], Loss: 0.2479\n",
      "Epoch [770/950], Loss: 0.8313\n",
      "Epoch [780/950], Loss: 0.6513\n",
      "Epoch [790/950], Loss: 0.9758\n",
      "Epoch [800/950], Loss: 0.8255\n",
      "Epoch [810/950], Loss: 0.4175\n",
      "Epoch [820/950], Loss: 0.6532\n",
      "Epoch [830/950], Loss: 0.5936\n",
      "Epoch [840/950], Loss: 0.4663\n",
      "Epoch [850/950], Loss: 0.7607\n",
      "Epoch [860/950], Loss: 0.2422\n",
      "Epoch [870/950], Loss: 0.5879\n",
      "Epoch [880/950], Loss: 0.6123\n",
      "Epoch [890/950], Loss: 0.4832\n",
      "Epoch [900/950], Loss: 0.8926\n",
      "Epoch [910/950], Loss: 0.6903\n",
      "Epoch [920/950], Loss: 1.1490\n",
      "Epoch [930/950], Loss: 1.0574\n",
      "Epoch [940/950], Loss: 0.6145\n",
      "Epoch [950/950], Loss: 0.6386\n"
     ]
    }
   ],
   "source": [
    "fit(950, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8472],\n",
       "        [1.8256],\n",
       "        [1.7160],\n",
       "        [1.6850],\n",
       "        [1.7921],\n",
       "        [1.8794],\n",
       "        [1.6263],\n",
       "        [1.8168],\n",
       "        [1.6260],\n",
       "        [1.8337],\n",
       "        [1.9486],\n",
       "        [1.7313],\n",
       "        [1.8045],\n",
       "        [1.5941],\n",
       "        [2.0824],\n",
       "        [1.9447],\n",
       "        [1.8819],\n",
       "        [1.8259],\n",
       "        [2.0408],\n",
       "        [1.7873],\n",
       "        [1.9854],\n",
       "        [1.7786],\n",
       "        [1.6248],\n",
       "        [1.8068],\n",
       "        [1.7294],\n",
       "        [1.8668],\n",
       "        [1.7736],\n",
       "        [1.8890],\n",
       "        [1.9023],\n",
       "        [1.7141],\n",
       "        [1.7693],\n",
       "        [1.9440],\n",
       "        [1.8343],\n",
       "        [1.9284],\n",
       "        [1.8337],\n",
       "        [1.8440],\n",
       "        [2.0177],\n",
       "        [1.8337],\n",
       "        [1.6140],\n",
       "        [1.8593],\n",
       "        [1.7841],\n",
       "        [1.7238],\n",
       "        [1.5886],\n",
       "        [1.7183],\n",
       "        [1.7635],\n",
       "        [1.7619],\n",
       "        [1.8080],\n",
       "        [1.6729],\n",
       "        [1.9062],\n",
       "        [1.8301],\n",
       "        [2.4155],\n",
       "        [2.1407],\n",
       "        [2.3632],\n",
       "        [1.9184],\n",
       "        [2.2332],\n",
       "        [1.9368],\n",
       "        [2.0630],\n",
       "        [1.7193],\n",
       "        [2.3056],\n",
       "        [1.7196],\n",
       "        [1.8111],\n",
       "        [1.9557],\n",
       "        [2.2072],\n",
       "        [2.0714],\n",
       "        [1.8873],\n",
       "        [2.3027],\n",
       "        [1.8264],\n",
       "        [2.0583],\n",
       "        [2.1825],\n",
       "        [1.9787],\n",
       "        [1.8626],\n",
       "        [2.1098],\n",
       "        [2.1844],\n",
       "        [2.1267],\n",
       "        [2.2226],\n",
       "        [2.2729],\n",
       "        [2.3806],\n",
       "        [2.2477],\n",
       "        [2.0089],\n",
       "        [2.0323],\n",
       "        [1.9496],\n",
       "        [1.9715],\n",
       "        [2.0170],\n",
       "        [2.0091],\n",
       "        [1.7415],\n",
       "        [1.9242],\n",
       "        [2.2795],\n",
       "        [2.2555],\n",
       "        [1.8715],\n",
       "        [1.8930],\n",
       "        [1.8991],\n",
       "        [2.0594],\n",
       "        [2.0290],\n",
       "        [1.7744],\n",
       "        [1.9089],\n",
       "        [1.9346],\n",
       "        [1.9260],\n",
       "        [2.1377],\n",
       "        [1.7721],\n",
       "        [1.9393],\n",
       "        [1.8631],\n",
       "        [1.8603],\n",
       "        [2.3266],\n",
       "        [2.0654],\n",
       "        [2.0512],\n",
       "        [2.5345],\n",
       "        [1.5499],\n",
       "        [2.4856],\n",
       "        [2.2847],\n",
       "        [2.2066],\n",
       "        [2.0729],\n",
       "        [2.1138],\n",
       "        [2.2018],\n",
       "        [1.8225],\n",
       "        [1.7411],\n",
       "        [1.9653],\n",
       "        [2.1383],\n",
       "        [2.4537],\n",
       "        [2.5831],\n",
       "        [2.0944],\n",
       "        [2.1750],\n",
       "        [1.7427],\n",
       "        [2.6230],\n",
       "        [2.0952],\n",
       "        [2.1200],\n",
       "        [2.4070],\n",
       "        [2.0407],\n",
       "        [1.9722],\n",
       "        [2.0566],\n",
       "        [2.4762],\n",
       "        [2.5207],\n",
       "        [2.5831],\n",
       "        [2.0353],\n",
       "        [2.1452],\n",
       "        [2.1037],\n",
       "        [2.5375],\n",
       "        [1.8743],\n",
       "        [2.0832],\n",
       "        [1.9304],\n",
       "        [2.2322],\n",
       "        [2.0821],\n",
       "        [2.1915],\n",
       "        [1.8603],\n",
       "        [2.1313],\n",
       "        [2.0348],\n",
       "        [2.1186],\n",
       "        [2.0986],\n",
       "        [2.0976],\n",
       "        [1.8544],\n",
       "        [1.8861]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d645e8fa0009817da80ecb09ec567d2cdd0e125efe9937bdceea2318054a9b0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('evn': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
